---
title: "Isn't that a TikTok song?"
author: "Anna Lau"
date: "9-2-2021"
# runtime: shiny
output:
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: "default"
    css: css_storyboard.css
    # logo: images/tiktok_logo.png
    favicon: images/tiktok_logo.png
# output: html_document
  
---
```{r, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```
```{r, echo = FALSE, result = FALSE, warning = FALSE}
library(spotifyr)
library(tidyverse)
library(plotly)
library(grid)
library(gridExtra)
library(compmus)
library(dplyr)
library(devtools)
library(tidyr)
library(tidyverse)
library(tidymodels)
library(ggdendro)
library(ggalt)
library(heatmaply)
library(spotifyr)
library(compmus)
```

```{r}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
} 
```
```{r}
mar <-get_playlist_audio_features("","0IIt2QOYxRawDHQbZ8ln3M") 
apr <-get_playlist_audio_features("","0PTklfVTalxE8j6T9NYZEG") 
may <-get_playlist_audio_features("","093VTj7Esn9nYiFQFoa1YH") 
jun <-get_playlist_audio_features("","2F3YMerEwMjXn3A4S7es6H") 
jul <-get_playlist_audio_features("","4U9w6uCKivCsRLHFyZgkxI") 
aug <-get_playlist_audio_features("","3zvNyJbb9rjdF0vag2O5xG")
sep <-get_playlist_audio_features("","2APegDsKij3yaL1ffG6Bz4") 
oct <-get_playlist_audio_features("","4np9mWC6T4O8x7hoxTeUPP") 
nov <-get_playlist_audio_features("","5xyKvHZIeWGAgWJ6ZEVm3H") 
dec <-get_playlist_audio_features("","4n90Xr0lxy1yLhbzTAgzTx") 

corpus <- 
  bind_rows(
    mar %>% mutate(category = "Mar"),
    apr %>% mutate(category = "Apr"),
    may %>% mutate(category = "May"),
    jun %>% mutate(category = "Jun"),
    jul %>% mutate(category = "Jul"),
    aug %>% mutate(category = "Aug"),
    sep %>% mutate(category = "Sep"),
    oct %>% mutate(category = "Oct"),
    nov %>% mutate(category = "Nov"),
    dec %>% mutate(category = "Dec")
  )

# Delete duplicate songs
corpus <- corpus[!duplicated(corpus$track.name),]
pop_sorted <- corpus[order(-corpus$track.popularity),]
```
```{r}
corpus$trend = c("dance",
"dance",
"dance",
"dance",
"transformation", 
"random", 
"dance",
"transformation",
"humour", 
"humour",
"dance",
"dance",
"humour",
"story telling",
"random",
"transformation",
"dance",
"humour",
"dance",
"dance",
"dance",
"dance",
"transformation",
"dance",
"humour",
"dance",
"transformation",
"dance", 
"dance",
"random",
"dance",
"dance",
"humour",
"random",
"story telling",
"dance",
"story telling",
"dance",
"dance",
"dance",
"dance",
"dance",
"humour",
"dance",
"story telling",
"humour",
"dance",
"random",
"dance",
"dance",
"dance",
"story telling",
"dance", 
"dance",
"dance",
"dance",
"dance",
"random",
"dance",
"story telling",
"transformation",
"dance",
"dance",
"random",
"dance",
"random",
"random",
"random",
"random",
"humour",
"dance",
"story telling",
"dance",
"story telling",
"transformation",
"random",
"random",
"dance",
"dance",
"random",
"story telling",
"dance",
"dance")
```

```{r}
corpus <- corpus %>%
  mutate(trends = ifelse(trend == "dance", "Dance", "Other"))
```

<!-- ### You think you popular huh? -->
```{r}
# popularity_plot <- corpus %>%
#   mutate(track.name = fct_reorder(track.name, track.popularity)) %>%
#   ggplot(aes(x=track.name, y=track.popularity)) +
#     geom_segment( aes(x = track.name, xend=track.name, y = 0, yend=track.popularity)) +
#     geom_point( size=1, color="skyblue") +
#     coord_flip() +
#     xlab("") +
#     ylab("Popularity")+
#     theme_minimal() +
#     # theme(
#     #   
#     # ) + 
#   labs(title = "Corpus track popularity",
#        y = "Popularity",
#        x = "")+
#   theme(
#     panel.grid.major.y = element_blank(),
#     panel.border = element_blank(),
#     axis.text.y = element_text(size = 4.5),
#     axis.ticks.y = element_blank(),
#     axis.ticks.x = element_blank(),
#   )
# 
# popularity_plot
```
```{r}
corpus<- corpus %>% mutate(poprange = case_when(
    between(track.popularity, 0, 50) ~ "Low",
    between(track.popularity, 51, 75) ~ "Middle",
    between(track.popularity, 76, 100) ~ "High",
    TRUE ~ NA_character_
  ))
```


### Okay... So is there anything specific about these trends? Tell me what is the *trend* of this TikTok song?

```{r}
corpus_features <-
  corpus %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(trends),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =  map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```
```{r}
corpus_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = corpus_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].
```
```{r}
corpus_cv <- corpus_features %>% vfold_cv(5)
```
```{r}
knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
corpus_knn <- 
  workflow() %>% 
  add_recipe(corpus_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```
```{r}
# corpus_knn %>% get_conf_mat()
```
```{r}
corpus_knn %>% get_conf_mat() %>% autoplot(type = "mosaic")
```

***

So yeah we cannot really predict what songs are supposed to fall into the *Dance* category and which fall into the *Other* category.


### Wow I cannot choose man, help me grow this tree and maybe we can figure it out.

```{r}
tree_model <-
  decision_tree() %>%
  set_mode("classification") %>% 
  set_engine("C5.0")
corpus_tree <- 
  workflow() %>% 
  add_recipe(corpus_recipe) %>% 
  add_model(tree_model) %>% 
  fit_resamples(
    corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )

# corpus_tree %>% get_pr()
```

```{r}
# workflow() %>%
#   add_recipe(corpus_recipe) %>%
#   add_model(tree_model) %>%
#   fit(corpus_features) %>%
#   pluck("fit", "fit", "fit") %>%
#   summary()
```

```{r}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
corpus_forest <- 
  workflow() %>% 
  add_recipe(corpus_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```

```{r}
# corpus_forest %>% get_pr()
```

```{r}
# workflow() %>%
#   add_recipe(corpus_recipe) %>%
#   add_model(forest_model) %>%
#   fit(corpus_features) %>%
#   pluck("fit", "fit", "fit") %>%
#   ranger::importance() %>%
#   enframe() %>%
#   mutate(name = fct_reorder(name, value)) %>%
#   ggplot(aes(name, value)) +
#   geom_col() +
#   coord_flip() +
#   theme_minimal() +
#   labs(x = NULL, y = "Importance")
```
```{r}
what <- corpus_features %>%
  filter(playlist == "Dance") 


gaa <- corpus_features %>%
  filter(playlist == "Other")

ac_12 <-corpus_features %>%
  ggplot(aes(x = acousticness, y = c12, colour = playlist, size = energy)) +
  geom_point(alpha = 0.8) +
  scale_color_viridis_d() +
  labs(
    x = "Acousticness",
    y = "12th Timbre component",
    size = "Energy",
    colour = "Playlist",
    title = "Higest importance"
  ) + 
  geom_encircle(aes(group = playlist))


temp_10 <- corpus_features %>%
  ggplot(aes(x = E, y = F, colour = playlist, size = energy)) +
  geom_point(alpha = 0.8) +
  scale_color_viridis_d() +
  labs(
    x = "tempo",
    y = "10th Timbre component",
    size = "Energy",
    colour = "Playlist",
    title= "Lowest importance"
  ) + 
  geom_encircle(aes(group = playlist))

my_layout <- rbind(c(1,2), c(1,2))

grid.arrange(grobs = c(list(ac_12), list(temp_10)), layout_matrix = my_layout,
             top = textGrob("Random forest",gp=gpar(fontsize=10,font=3)))
```


*** 

| Class | Precision | Recall |
|-------|-----------|--------|
| Dance | 0.590     | 0.750  |
| Other | 0.593     | 0.410  |

Expected *Highest importance* plot to have **more distinction** between the two trends *Dance* and *Other*. For the *Lowest importance* plot excepted to have  **no distinction** between the two trends. However, as you can see bu the encircled parts. there is a lot of overlap between *Dance* and *Other*, hence this classification does not really work, despite having relatively high importance for Acoustiness and the 12th timbre component (bove above a score of 2.0). However from the table we can also see that the classification model did not managed to find a pattern that makes tracks specifically a Dance or Other song. 

### Homework week 10 - Tempogram

```{r}
play_date <- get_tidy_audio_analysis("4DpNNXFMMxQEKl7r0ykkWA")
```
```{r}
play_date_cyclic <- play_date %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Play Date - Melanie Martinez (Cyclic)") +
  scale_x_continuous(breaks = seq(0,180, 30) ) + 
  geom_vline(xintercept = 132, color = "white")+
  geom_vline(xintercept = 136, color = "white")+
  geom_vline(xintercept = 165, color = "white")+
  theme_classic()

play_date_cyclic
```

***

The tempogram of the song *Play Date* by Melanie Martinez, shows that there are small tempo variations throughout the entire song. Very notable is the change in tempo between 132 - 136 seconds(2:12 - 2:16). The part in the song corresponding to this time frame is actually almost silent. It is surprising that Spotify labels this silent part to have a high tempo. At the end of this time frame slow beating comes in again, hence we see the yellow line in the time frame go down again. Once after we see that the tempo goes back to the usual. At the very end, the song slows down and fades out, this corresponds to the last few seconds where we see that the tempogram is slightly lighter again. 

### Homework week 10 Tempogram

```{r}
rhythm_thief <- get_tidy_audio_analysis("78HutMlGCBJUIv6ckenQxV")
```
```{r}
rhythm_thief_tempogram_yes_cyclic <- rhythm_thief %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)", title = "Rhythm Thief but Cursed - Headass") +
  theme_classic()

rhythm_thief_tempogram_yes_cyclic
```

*** 

This is a very strange song which consists of random sounds put together. Surprisingly, the tempo stays very consistent throughout the entire track.

### Pump the beat! If the **tempo** is too slow I don't want to dance.
```{r}
corpus %>%
  # mutate(trends = ifelse(trend == "dance", "Dance", "Other")) %>%
  ggplot(aes(x = tempo)) +
  geom_histogram(binwidth = 1, fill = "skyblue") +
  facet_wrap(~trends) +
  scale_x_continuous(breaks = seq(60, 180, 30))+ 
  # geom_vline(xintercept = 120, color = "black")+
  # geom_vline(xintercept = 122, color = "black")+
  labs(x = "Tempo (BPM)", y = "Frequency") + theme_light()

# corpus %>%
#   mutate(trends = ifelse(trend == "dance", "Dance", "Other")) %>%
#   ggplot(aes(x = tempo)) +
#   geom_histogram(binwidth = 2, fill = "skyblue") +
#   facet_wrap(~trends) +
#   labs(x = "Tempo (BPM)", y = "Frequency")
```

***

So do the dance song satisfy our expectations? For the dance songs we'd assume that the beat would be around 110-130 BPM. The majority of the dance songs fall within the tempo range of 110-130 BPM. 


### Homework week 9 

```{r}
dance_counts <- corpus %>%
  filter(trends == "Dance")%>%
    count(key_name) %>%
      mutate(perc = n/sum(n), trends = "Dance")
  
other_counts <- corpus %>%
  filter(trends == "Other")%>%
    count(key_name) %>%
      mutate(perc = n/sum(n), trends = "Other")

rbind(dance_counts, other_counts) %>%
  ggplot(aes(x = key_name, y = perc)) +
    geom_bar(stat = "identity", fill = "skyblue") + 
      facet_wrap(~trends)+
        labs(title = "Distribution of keys in the corpus",
             x = "Key",
             y = "Normalised Frequency") + theme_light()
```

***

Given the trends in the corpus, these normalised histograms are made based on the key that was found by the Spotify API. Overall we can see that there is quite some similarity between the different trends. For example both both trends indicate that within the trend most songs have either a **C#** or a **G** key. Moreover the majority of the keys used in both trend categories are **A#**, **B**, **C**, **C#**, **G**, and **G#** which all have a score of higher than 0.075. The only huge dissimilarity between the trends that can be seen are within the key **D**: for "dance"-tracks there is a 0.1125 score for **D** whereas for "other"-tracks there is only a 0.023 score. 

### Homework 9 part two

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```
```{r}
classical <-
  get_tidy_audio_analysis("2mRUmSG3XGjFloqgAT2UJN") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

savage <-
  get_tidy_audio_analysis("4Oun2ylbjFKMPTiaSbbCih") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```
```{r}
classical %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "angular",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Eine Kleine Nachtmusik K. 525. Allegro - Mozart") + 
  geom_hline(yintercept = "G:maj", color = "white") +
  geom_hline(yintercept = "D:maj", color = "white")  + 
  geom_hline(yintercept = "E:maj", color = "red")+
  geom_vline(xintercept = 150, color = "white")+
  geom_vline(xintercept = 195, color = "white")
```

***

Here we have a chordogram of the song *Eine kleine Nachtmusik K.* - Wolfgang Amadeus Mozart, which is an outlier in the corpus in the sense that it is the only classical piece in the corpus. On the [Wikipedia website](https://en.wikipedia.org/wiki/Eine_kleine_Nachtmusik) of this well-known song it states that this piece has four movements i.e. G major - D major - Ambiguous key - G major, which are indicated with horizontal white stripes. However, if we look in the chordogram we see that the piece is found to be written in Emajor, indicated with a horizontal red line. In harmony theory the Emajor key is most similar to **C#minor** but this chord isn't as dark as the Emajor one. Between time steps 150 - 195 (2:30 - 3:15)(the vertical white lines), we see that the keys F major, Eb major and F# minor are darker coloured. Maybe the spotify API did not estimate the chords well because of the instruments: string instruments. 


### Homeowork 9 part 3

```{r}
savage %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "", title = "Savage - Megan Thee Stallion") + 
  geom_hline(yintercept = "Eb:min", colour = "white")
```

*** 

Throughout the entire song two chords are constantly played namely **Eb7** and **E7**. The **Eb7** chord is the most dark throughout the entire track on the chordogram. We can also see that the **E7** chord is every now and then dark. It is not strange that the **B7** is also darkly coloured throughout the almost the entire track because an as it is in harmony with the **E7** chord. 

### Yeah you've heard this song before, but where did it come from?
The corpus for this project is a playlist from Spotify. [This playlists](https://open.spotify.com/playlist/5kQyvWFk8r1y2IQEtjBfey?si=HLNnUJzYQHSVYq7ub3lbRA) is a collection of songs that are famous from TikTok - a social media app used to make short-form videos. In these 15 seconds videos, music is played and people dance, lip-sync, tell stories, make humorous memes, and do all other kinds of trends. As the spaces people normally enjoy music were impacted by the pandemic, TikTok helped fill the need for communal musical experience all over the world. Starting from the beginning of the pandemic, March 2020, TikTok gained a lot of popularity. Hence the songs from the corpus will be the top 10 songs on TikTok from March 2020 till December 2020. The top songs are acquired from [this website](https://tokboard.com/months). 

I want to find out how different these popular TikTok songs are from one another. The genres of the songs are quite diverse. Maybe there is a factor that is a core element of becoming a suitable TikTok song. In addition, as TikTok videos have a wide variety of trends, I want to find out what the similarities and differences are within a trend. More specifically I will be focusing on the *Dance* trend as that is the biggest on TikTok.

Interesting comparison points in the corpus of this project will be the overall mood of a song. Psychologist Robert Thayer's came up with a traditional model of mood. Where songs can be categorised along the lines of energy and stress, from happy to sad and calm to energetic (Bhat et al 359). Next to these 4 categories there are also 4 sub categories e.g. Happy - energetic, Happy - calm, etc. I assume the corpus has a lot of Happy, Energetic, Happy - Energetic and a few Happy - Calm and Calm songs. The reason for that is because many songs are for funny and trendy TikTok-challenges. It is expected that the intensity for Energetic and Happy - Energetic songs are on the higher spectrum than Happy - Calm and Calm songs. Another musical component that can be looked at is the Timbre of a song. Timbre is the tonal quality of a piece created by harmonics. It is to no surprise that these will be different between moods as well. Happy, Happy - Energetic and Energetic songs will have around a medium timbre. Whereas Calm and Happy - Calm songs will most likely have a low timbre. The pitch intervals of the songs will probably vary quite a lot between the mood categories, as it is very dependent on the singer's voice, and the instruments that are used. Lastly the rhythm of songs with a Happy, Happy - Energetic and Energetic mood will most likely be high paced, whereas Calm and Calm - Happy songs will have a more relaxed and slow rhythm. 

TikTok is a very creative platform where people use all kinds of remix songs which aren't accessible on Spotify although they are very popular songs. In the following table popular songs that were *not* listed on Spotify are shown.

| Song Title                                | Month    | Rank |
|-------------------------------------------|----------|:----:|
| #hiteverybeat                             | March    | 3    |
| Over it Chinese New year Remix by JohhnyG | March    | 4    |
| 2liveSoundsmix                            | March    | 7    |
| Original sound - KTM                      | March    | 9    |
| Kanta Laga Mix                            | April    | 9    |
| Original sound - Plks choudhary           | April    | 10   |
| Cari Mama Muda                            | May      | 7    |
| Kream bebiisan edition                    | May      | 8    |
| original sound                            | May      | 11   |
| ओरिजिनल साउंड                              | June     | 6    |
| Gimme clout pls                           | June     | 7    |
| Original sound                            | October  | 1    |
| Viva La Swing                             | October  | 5    |
| ... is sweaty                             | November | 8    |

Some songs are listed multiple times in the top ten of the months, these are listed in the following table <br/>

| Song Title                |         Months       | Repetition |
|-------------------------- | :-------------------:|:----------:|
| Savage                    |   Mar - Apr - May    |     3      |
| Roses                     |      Mar - Apr       |     2      |
| Laxed (Siren Beat)        |      Apr - May       |     2      |
| Play Date                 |      Apr - May       |     2      |
| Coño                      |      May - Jun       |     2      |
| Love Story                |      Jul - Aug       |     2      | 
| How you like that         |      Jul - Aug       |     2      |
| WAP                       |      Aug - Sept      |     2      | 
| Monkeys Spinning Monkeys  |Jul - Oct - Nov - Dec |     4      | 
| Oh no                     |      Nov - Dec       |     2      | 
| It's Tricky               |      Nov - Dec       |     2      | 
| Classical Music           |   Aug - Oct - Nov    |     3      | 
| Adderall                  |      Nov - Dec       |     2      |

Lastly, a final note needs to be made on the length of the TikTok videos. These videos can only be up to 15 seconds long. However, in this research the full length of the songs are used. The motivation behind this is because 15 does not allow for a thoroughly and detailed analysis between the songs. 

**Atypical songs in the corpus**

* *Eine kleine Nachtmusik K.* - Wolfgang Amadeus, stands out a lot from the rest. It is the only classical piece in the corpus and is composed in the year 1787. 
* *Steven Universe* - L.Dre: one of the few slow paced songs, and it is only 2.14 minutes long  without lyrics. 
* *Monkeys Spinning Monkeys* - Keving MacLeod, one of the few songs that have no lyrics also very short 
* Funny to see that from December there are seasonal songs e.g. *All I Want for Christmas is You* - Mariah Carey and *Jinge Bell Rock* - Bobby Helms. 

**Note**
The Song Titles in the table are copied from [the website](https://tokboard.com/months)

***

Here is the playlist that represents the corpus:
<iframe src="https://open.spotify.com/embed/playlist/5kQyvWFk8r1y2IQEtjBfey" width="280" height="380" frameborder="0" allowtransparency="true" allow="encrypted-media"></iframe>

**Making the playlist**
If a song in the top 10 of the month was not available on Spotify, the song is skipped and the 11th song was added. If a song was repeatedly listed in the top 10 the song was skipped. This resulted in a total of 83 songs a total of 4 hours and 9 minutes. 

**Setting up the trends per song**
The majority of the songs are associated with dance challenges, hence these songs are categorised under the *Dance* trend. All the other trends are referenced as *Other*.

### Ain't that strange that I want to move my body to these songs. 
```{r}
dance_tracks <- c("What You Know Bout Love", "WAP (feat. Megan Thee Stallion)",
          "Roses - Imanbek Remix", "TKN (feat. Travis Scott)",
          "You Got It", "Toosie Slide",
          "Shower", "How You Like That",
          "Supalonely", "Party Girl")
dance_songs <- corpus %>%
  filter(track.name %in% dance_tracks)

danceVSenergy <- ggplot(corpus, aes(x = danceability, y = energy, size = tempo)) +
  geom_point() +
  geom_point(data = dance_songs,
             aes(x = danceability,
                 y = energy,
                 color = track.name,
                 size = tempo
                 )
             )+
  geom_rug(size = 0.1) +      # Add 'fringes' to show data distribution.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  theme_light()+
  # ylim(0,1.0) +
  # xlim(0,1.0) +
  labs(x = "Danceability",
       y = "Energy",
       size = "Tempo",
       color = "Track")

# ggplotly(danceVSenergy)
danceVSenergy
```

***

One of the biggest trends of TikTok are the *Viral Dances* almost everybody just had to learn. Here, a graphic displays how danceable a track is. This is broken down into Danceability, Energy and Tempo features from the [Spotify API](https://developer.spotify.com).

To no surprise does the majority of the tracks have a high danceability as most TikTok songs are dance challenges. Zooming in into the top 10 dance songs, the coloured dots have a danceability mean of 0.78. It is on the higher side, but not the highest. The reason for this can be that these songs have a fairly easy choreography, so that everyone can enjoy dancing to them together on TikTok. Increasing the difficulty of a choreography would probably lower the popularity, as less people would be able to perform the dance. Tracks with a higher danceability score often not labelled as dance songs. The track with the lowest danceability score of 0.676 is *Steven Universe* - L.Dre which is a low-fi hiphop song often used as background music for the TikTok video. The track with the highest danceability score is used for a dance challenge trend on TikTok. 

The track with the highest energy is *Mere Sapno Ki Rani - Tik Tok Remix* - from Eduardo Luzquiños ranked as penultimate of all songs in this corpus. There is no real trend linked to this song. 

### Are you in the *mood*, because I certainly am.

```{r}
ggplot(corpus, aes(x = energy, y = valence, shape = trends)) + 
  geom_point(aes(shape = trends, color = trends)) + 
  scale_color_manual(values = c("#9FBEE1", "#1E3D60"))+
  theme_light() +
   scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.5, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.5, 1),
    minor_breaks = NULL
  ) +
  geom_vline(xintercept = 0.5, linetype="dotted", color = "black", alpha = 0.7) + 
  geom_hline(yintercept = 0.5, linetype="dotted", color = "black", alpha = 0.7) + 
  annotate("text", 0.05, 0.05, label = "Sad", color = "black", alpha = 0.7, fontface="bold") +
  annotate("text", 0.05, 0.95, label = "Angry", color = "black", alpha = 0.7, fontface="bold") +
  annotate("text", 0.95, 0.05, label = "Calm", color = "black", alpha = 0.7, fontface="bold") +
  annotate("text", 0.95, 0.95, label = "Happy", color = "black", alpha = 0.7, fontface="bold") +
  labs(x = "Energy", y = "Valence", title = "The mood of the song", shape = "Trends", color = "Trends")
```

***

Here follows a analysis of this plot


### #bananadrop Where did my sunglasses go? 

```{r}
bananas <- corpus %>% 
  filter(str_detect(corpus$track.name, "Banana"))

library(compmus)

## Conkarah, Shaggy
banana_orig <-
  get_tidy_audio_analysis("13OdVDwHdPlGkKHyjPoadB") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
## Conkarah, Shaggy, DJ Fle
banana_remix <-
  get_tidy_audio_analysis("0dZpw3h6KZhcHec61qwevZ") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

banana_dtw <- compmus_long_distance(
  banana_orig  %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  banana_remix %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  feature = pitches,
  method = "angular"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "Original", y = "Remix", title = "Banana song") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

banana_orig_chroma <- banana_orig %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Original Banana song") +
  theme_minimal() +
  scale_fill_viridis_c()

banana_remix_chroma <- banana_remix %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Remix Banana song") +
  theme_minimal() +
  scale_fill_viridis_c()
```


```{r}
my_layout <- rbind(c(1,3), c(1,3), c(1,3), c(2,3), c(2,3), 
                   c(2,3))

grid.arrange(grobs = c(list(banana_orig_chroma, banana_remix_chroma), list(banana_dtw)), layout_matrix = my_layout)

```


***


Plotted with Euclidean normalisation and angular distance. When listening to the songs, it does not seem like there is much difference between the two. Only the remix version is 26 seconds longer than the original Banana song and the last 17 seconds are silent. However, the Dynamic Time Warping of the chromagrams does not show that that the songs are the same.   

### Okay but what about those 15 seconds, are they any different than the rest of the song? (pt.1)
```{r}
TKN <-
  get_tidy_audio_analysis("4w47S36wQGBhGg073q3nt7") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )


ssm_pitch <- TKN %>%
  compmus_self_similarity(pitches, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Pitches SSM") +
  geom_vline(xintercept = 63, color = "black") + 
  geom_vline(xintercept = 78, color = "black")

ssm_timbre <- TKN %>%
  compmus_self_similarity(timbre, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre SSM") +
  geom_vline(xintercept = 63, color = "black") +
  geom_vline(xintercept = 78, color = "black")

my_layout <- rbind(c(1,2), c(1,2))

grid.arrange(grobs = c(list(ssm_pitch), list(ssm_timbre)), layout_matrix = my_layout,
             top = textGrob("TKN - ROSALÍA, Travis Scott",gp=gpar(fontsize=20,font=3)))

```

***
 
On the left you can see two self-similarity matrices (SSM) for the *TKN (feat. Travis scott)* - ROSALÍA, Travis Scott. Let's dissect these plots separately.

First we have the SSM based on pitches. There is a slight checkerboard pattern going on. That is to no surprise as: the first 25 seconds of the song is mostly ROSALÍA sining with a very subtle melody playing in the back. After those 25 seconds a clear drum sound is added that plays through the next 31 seconds (0:25 - 0 :56). It is visible that throughout those 31 seconds the song does not really change that much as the block stays pretty much consistently the same colour, hence there is homogeneity. This checkerboard pattern sort of repeats itself throughout the song. Between 56 - 66 seconds (0:56 - 1:06) and 81 - 96 seconds (1:21 - 1:36) we see a slighly lighter blue. In these parts only Travis is singing with a sort of autotune voice. This autotune without the beats might result in a slightly different pitch than the parts before and after this. Very noticeable is the bright yellow/light green stripe near the end of the song on the pitches SSM between 113-115 seconds (1:53- 1:55). In the song we hear a clear sort of clap sound, which can relate to all pitches in a chromagram (?It's based on a chromagram right?). Hence it isn't strange that all the bright line occures in the SSM based on pitches. However, we would have expected such a bright line also around 31-33 seconds as there is a similar clap sound in the track. 

Moving on to the second SSM. The song begins with a melody that contains no drums in the first 3 seconds. This apparently has a different timbre than the rest of the song. Then between 31-33 there is a slight lighter stripe, this is actually the first clap sound that didn't show up in the SSM based on pitches. Again around 56-66 seconds (0:56 - 1:06) and 81-96 seconds (1:21 - 1:36) we see lighter colours in the SSM. Appararently, those autotuned singing parts of Travis result in a different Timbre. Moreover since the beat is very much in the background/not there this is also different timbre than the rest of the song. Lastly, on 115 seconds there is a very bright stripe visible in the SSM. This corresponds again to the clap in the song. 

The 15 seconds used on TikTok are between 63 - 78 seconds (1:03 - 1:18), which is mostly used for a dance trend. This part is marked between two black lines(should I leave black?) on the two SSMs. For both SSM we see that the colour is not much different than the rest in the SSM. This indicates that the 15 seconds used for the TikTok resembles the entire song pretty well. 

### Okay but what about those 15 seconds, are they any different than the rest of the song? (pt. 2)

```{r}
TKN <-
  get_tidy_audio_analysis("7eJMfftS33KTjuF7lTsMCx") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )


ssm_pitch <- TKN %>%
  compmus_self_similarity(pitches, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Pitches SSM") +
  geom_vline(xintercept = 0, color = "black") + 
  geom_vline(xintercept = 15, color = "black")

ssm_timbre <- TKN %>%
  compmus_self_similarity(timbre, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre SSM") +
  geom_vline(xintercept = 0, color = "black") +
  geom_vline(xintercept = 15, color = "black")

my_layout <- rbind(c(1,2), c(1,2))

grid.arrange(grobs = c(list(ssm_pitch), list(ssm_timbre)), layout_matrix = my_layout,
             top = textGrob("Death bed (coffee for your head) - Powfu, beabadoobee",gp=gpar(fontsize=20,font=3)))

```

### Okay but what about those 15 seconds, are they any different than the rest of the song? (pt. 3)

```{r}
TKN <-
  get_tidy_audio_analysis("2kefHjNepGePZG4WxH2Vh4") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "manhattan"              # Change summary & norm.
      )
  )


ssm_pitch <- TKN %>%
  compmus_self_similarity(pitches, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Pitches SSM") +
  geom_vline(xintercept = 0, color = "black") + 
  geom_vline(xintercept = 15, color = "black")

ssm_timbre <- TKN %>%
  compmus_self_similarity(timbre, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "", title = "Timbre SSM") +
  geom_vline(xintercept = 0, color = "black") +
  geom_vline(xintercept = 15, color = "black")

my_layout <- rbind(c(1,2), c(1,2))

grid.arrange(grobs = c(list(ssm_pitch), list(ssm_timbre)), layout_matrix = my_layout,
             top = textGrob("#WIPEITDOWN - BMW KENNY",gp=gpar(fontsize=20,font=3)))

```

### Conclusion
